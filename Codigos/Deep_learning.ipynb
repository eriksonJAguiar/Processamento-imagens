{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial de Deep Learning -- Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar as bibliotecas para carregar os dados com o pytorch\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets, utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base MNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carregar as imagens da MNist e normalizar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicar a normalização na imagem\n",
    "tf_image = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Lambda(lambda x: x.repeat(3, 1, 1)), \n",
    "                               transforms.Normalize((0.5,), (0.5,))])\n",
    "#importar a mnist\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=tf_image)\n",
    "test_datset = datasets.MNIST(root='./data', train=False, download=True, transform=tf_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consultar o número de exemplos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num exemplos no treino: 60000\n",
      "num exemplos no teste: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"num exemplos no treino: {len(train_dataset)}\")\n",
    "print(f\"num exemplos no teste: {len(test_datset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mostrar alguns exemplos de imagens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1875/1875 [36:59<00:00,  1.18s/it, v_num=7, loss=2.350, acc=0.113, f1_score=0.020] \n",
      "                                                                   \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mostrar as imagens\n",
    "num_row = 2\n",
    "num_col = 5\n",
    "\n",
    "plt.figure(figsize=(1.5*num_col,2*num_row))\n",
    "for i in range(10):\n",
    "    image, label = train_dataset[i]\n",
    "    plt.subplot(num_row,num_col,i+1)\n",
    "    plt.imshow(image[0].reshape(28,28), cmap='gray')\n",
    "    plt.title('Label: {}'.format(label))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformar dados em um dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, num_workers=8, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_datset, batch_size=32, num_workers=8, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de imagens de CT-Scan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criar o custom dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "        classe para importar imagens de uma classe especifica\n",
    "        fonte: https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images\n",
    "        params:\n",
    "            - path: caminho para o repositório de imagens\n",
    "            - tf_image: normaliza a imagem\n",
    "    '''\n",
    "    def __init__(self, path, tf_image, train=True, test=False, val=False):\n",
    "        \n",
    "        #selecionar a partição de dados que será coletada da pasta\n",
    "        if test:\n",
    "            self.data = ImageFolder(root=os.path.join(path, 'test'), transform=tf_image)\n",
    "        elif val:\n",
    "            self.data = ImageFolder(root=os.path.join(path, 'valid'), transform=tf_image)\n",
    "        else:\n",
    "            self.data = ImageFolder(root=os.path.join(path, 'train'), transform=tf_image)\n",
    "        \n",
    "        # self.X = []\n",
    "        # self.y = []\n",
    "        \n",
    "        # self.X, self.y = zip(*[(x, y) for x, y in self.dataset])\n",
    "        \n",
    "        # self.X = torch.stack(list(self.X))\n",
    "        # self.y = torch.tensor(list(self.y))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx][0]\n",
    "        y = self.data[idx][1]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_image = transforms.Compose([ transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor(),  \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ct = CTDataset(path=\"./data/CT/\", tf_image=tf_image, train=True)\n",
    "test_data_ct = CTDataset(path=\"./data/CT/\", tf_image=tf_image, train=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_ct = torch.utils.data.DataLoader(train_data_ct, batch_size=32, num_workers=8, shuffle=True)\n",
    "test_loader_ct = torch.utils.data.DataLoader(test_data_ct, batch_size=32, num_workers=8, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir o modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo customizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    #Inicialização da rede\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        #A camada convolucional de entrada recebe a image de input e tem como saíde 10 canais\n",
    "        9# n_out = [(input_size + 2*padding - kernel)/stride]+ 1\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        # A conv 2 tem como entrada os 16 canais da anteriror\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "        )\n",
    "        #camadas conectadas\n",
    "        self.fc1 = torch.nn.Linear(32*7*7, 50)\n",
    "        #A ultima camada contém o numero de classes\n",
    "        self.fc2 = torch.nn.Linear(50, 10)\n",
    "        self.activation = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #add a conv 1\n",
    "        x = self.conv1(x)\n",
    "        #add a conv 2\n",
    "        x= self.conv2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo a partir da ResNet50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar as arquiteura limpa\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.resnet import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criação e modificação do modelo\n",
    "# Definição do modelo base pre-treinado na ImageNet\n",
    "model_resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "#Alteração das camadas para adicionar a camada que representa o número de classes\n",
    "model_resnet.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model_resnet.fc.in_features, 10),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inicializando a rede**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MyNet()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**importar as bibliotecas de treinamento o pytorch lightning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchmetrics import Accuracy, F1Score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe para o treinamento do modelo com o pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTestModel(L.LightningModule):\n",
    "    '''\n",
    "        Classe para configuração do treinamento do modelo\n",
    "        params:\n",
    "            - model: model base para o treinamento\n",
    "            - lr: taxa de aprendizado\n",
    "    '''\n",
    "    def __init__(self, model, lr):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        \n",
    "        #definindo a função de perda\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        #configuração das metricas\n",
    "        self.train_acc = Accuracy(task='multiclass', num_classes=10)\n",
    "        self.test_acc = Accuracy(task='multiclass', num_classes=10)\n",
    "        \n",
    "        self.train_f1 = F1Score(task=\"multiclass\", num_classes=10, average=\"macro\")\n",
    "        self.test_f1 = F1Score(task=\"multiclass\", num_classes=10, average=\"macro\")\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #coleta os labels e imagens o batch\n",
    "        x, y = batch\n",
    "        \n",
    "        #resultado da saida da rede, que é a softmax\n",
    "        outputs = self.forward(x)\n",
    "        \n",
    "        #calculando a perda\n",
    "        y_true = y.squeeze()\n",
    "        loss_value = self.loss(outputs, y_true)\n",
    "        \n",
    "        #coletando os labels preditos\n",
    "        y_pred = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        acc = self.train_acc(y_pred, y_true)\n",
    "        f1 = self.train_f1(y_pred, y_true)\n",
    "        \n",
    "        self.log('loss', loss_value.item(), prog_bar=True)\n",
    "        self.log('acc', acc, prog_bar=True)\n",
    "        self.log('f1_score', f1, prog_bar=True)\n",
    "        \n",
    "        \n",
    "        return loss_value\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        #coleta os labels e imagens o batch\n",
    "        x, y = batch\n",
    "        \n",
    "        #resultado da saida da rede, que é a softmax\n",
    "        outputs = self.forward(x)\n",
    "        \n",
    "        #calculando a perda\n",
    "        y_true = y.squeeze()\n",
    "        loss_value = self.loss(outputs, y_true)\n",
    "        \n",
    "        #coletando os labels preditos\n",
    "        y_pred = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        acc = self.test_acc(y_pred, y_true)\n",
    "        f1 = self.test_f1(y_pred, y_true)\n",
    "        \n",
    "        self.log('val_loss', loss_value.item(), prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        self.log('val_f1_score', f1, prog_bar=True)\n",
    "        \n",
    "        return loss_value\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        return [opt]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução do Treinamento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treinamento para o model customizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/eriksonaguiar/codes/SCC0651-2-ProcessamentoImagens/Codigos/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | MyNet              | 92.2 K\n",
      "1 | loss      | CrossEntropyLoss   | 0     \n",
      "2 | train_acc | MulticlassAccuracy | 0     \n",
      "3 | test_acc  | MulticlassAccuracy | 0     \n",
      "4 | train_f1  | MulticlassF1Score  | 0     \n",
      "5 | test_f1   | MulticlassF1Score  | 0     \n",
      "-------------------------------------------------\n",
      "92.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "92.2 K    Total params\n",
      "0.369     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1875/1875 [00:12<00:00, 153.76it/s, v_num=0, loss=2.350, acc=0.113, f1_score=0.020]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1875/1875 [00:12<00:00, 153.68it/s, v_num=0, loss=2.350, acc=0.113, f1_score=0.020]\n",
      "{'loss': tensor(2.3476), 'acc': tensor(0.1135), 'f1_score': tensor(0.0200)}\n"
     ]
    }
   ],
   "source": [
    "# carregar o module de treinamento\n",
    "ligth_train = TrainTestModel(model=network, lr=0.01)\n",
    "\n",
    "#configuração do early stopping\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5, mode='max')\n",
    "\n",
    "#configuração do tensorboard para salvar os experimentos\n",
    "#logger = TensorBoardLogger(save_dir=\"logs\", name=\"my-model\")\n",
    "\n",
    "#modulo para execução do treinamento\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu',\n",
    "    devices='auto',\n",
    "    min_epochs=5,\n",
    "    #logger=logger,\n",
    "    #callbacks=[early]\n",
    ")\n",
    "\n",
    "#executar o treinamento e teste\n",
    "trainer.fit(\n",
    "    model=ligth_train,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=test_loader\n",
    ")\n",
    "\n",
    "metrics = trainer.logged_metrics\n",
    "print(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treinamento com a ResNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | ResNet             | 23.5 M\n",
      "1 | loss      | CrossEntropyLoss   | 0     \n",
      "2 | train_acc | MulticlassAccuracy | 0     \n",
      "3 | test_acc  | MulticlassAccuracy | 0     \n",
      "4 | train_f1  | MulticlassF1Score  | 0     \n",
      "5 | test_f1   | MulticlassF1Score  | 0     \n",
      "-------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1875/1875 [00:47<00:00, 39.41it/s, v_num=3, loss=1.480, acc=0.981, f1_score=0.952]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1875/1875 [00:48<00:00, 38.95it/s, v_num=3, loss=1.480, acc=0.981, f1_score=0.952]\n",
      "{'loss': tensor(1.4805), 'acc': tensor(0.9806), 'f1_score': tensor(0.9524)}\n"
     ]
    }
   ],
   "source": [
    "# carregar o module de treinamento\n",
    "ligth_train = TrainTestModel(model=model_resnet, lr=0.001)\n",
    "\n",
    "#configuração do early stopping\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5, mode='max')\n",
    "\n",
    "#configuração do tensorboard para salvar os experimentos\n",
    "#logger = TensorBoardLogger(save_dir=\"logs\", name=\"my-model\")\n",
    "\n",
    "#modulo para execução do treinamento\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu',\n",
    "    devices='auto',\n",
    "    min_epochs=5,\n",
    "    #logger=logger,\n",
    "    #callbacks=[early]\n",
    ")\n",
    "\n",
    "#executar o treinamento e teste\n",
    "trainer.fit(\n",
    "    model=ligth_train,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=test_loader\n",
    ")\n",
    "\n",
    "metrics = trainer.logged_metrics\n",
    "print(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treinamento para a base de CT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | ResNet             | 23.5 M\n",
      "1 | loss      | CrossEntropyLoss   | 0     \n",
      "2 | train_acc | MulticlassAccuracy | 0     \n",
      "3 | test_acc  | MulticlassAccuracy | 0     \n",
      "4 | train_f1  | MulticlassF1Score  | 0     \n",
      "5 | test_f1   | MulticlassF1Score  | 0     \n",
      "-------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eriksonaguiar/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 20/20 [00:05<00:00,  3.80it/s, v_num=4, loss=2.060, acc=0.390, f1_score=0.0674]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 20/20 [00:05<00:00,  3.43it/s, v_num=4, loss=2.060, acc=0.390, f1_score=0.0674]\n",
      "{'loss': tensor(2.0565), 'acc': tensor(0.3905), 'f1_score': tensor(0.0674)}\n"
     ]
    }
   ],
   "source": [
    "# carregar o module de treinamento\n",
    "ligth_train = TrainTestModel(model=model_resnet, lr=0.001)\n",
    "\n",
    "#configuração do early stopping\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5, mode='max')\n",
    "\n",
    "#configuração do tensorboard para salvar os experimentos\n",
    "#logger = TensorBoardLogger(save_dir=\"logs\", name=\"my-model\")\n",
    "\n",
    "#modulo para execução do treinamento\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu',\n",
    "    devices='auto',\n",
    "    min_epochs=5,\n",
    "    #logger=logger,\n",
    "    #callbacks=[early]\n",
    ")\n",
    "\n",
    "#executar o treinamento e teste\n",
    "trainer.fit(\n",
    "    model=ligth_train,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=test_loader\n",
    ")\n",
    "\n",
    "metrics = trainer.logged_metrics\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
